# Zotero Summary Creator

> Generate AI-powered academic paper summaries with Text-to-Speech playback using local LLM (Ollama)

**Features:**
- ğŸ¤– Generate structured summaries with executive summary, contributions, limitations, and innovation opportunities
- ğŸ”Š Text-to-Speech (TTS) playback for summaries, abstracts, and full papers
- ğŸ  100% local processing - no cloud services, no tracking
- âš¡ Automatic Ollama server management (starts/stops as needed)
- ğŸ“š Batch processing for multiple papers
- ğŸ¨ Customizable prompts and models

---

## Quick Start

### 1. Install Prerequisites

**Install Ollama:**
```bash
# macOS/Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Or download from https://ollama.ai

# Pull a model (choose based on your available VRAM)
ollama pull qwen3:0.6b   # Fastest, ~512MB VRAM (recommended for laptops)
ollama pull qwen3:4b     # Good quality, ~2.5GB VRAM (default)
ollama pull llama2       # Alternative, ~4GB VRAM
```

**Requirements:**
- macOS (recommended), Linux, or Windows
- Zotero 6 or 7
- Node.js (for building the plugin)
- Ollama with sufficient VRAM for your chosen model

### 2. Build & Install Plugin

```bash
# Clone the repository
git clone https://github.com/yourusername/zotero-summary-creator.git
cd zotero-summary-creator

# Install dependencies
npm install

# Build the plugin
npm run build
```

**Install in Zotero:**
1. Open Zotero
2. Go to **Tools â†’ Add-ons** (or âŒ˜â‡§A / Ctrl+Shift+A)
3. Click the **gear icon** (âš™ï¸) â†’ **Install Add-on From File...**
4. Select `build/zotero-summary-creator.xpi`
5. Click **Install Now** and restart Zotero

### 3. Configure

**View Current Settings:**
- Go to **Tools â†’ Summary Creator: Show Current Settings**

**Change Settings** (using Zotero Config Editor):
1. Go to **Edit â†’ Settings â†’ Advanced â†’ Config Editor**
2. Click **"I accept the risk!"**
3. Search for: `extensions.summarycreator.ollamaModel`
4. Double-click it and change to: `qwen3:4b` (default) or `qwen3:0.6b` (faster)
5. Click **OK** and restart Zotero

**Default Settings:**
- **Ollama URL**: `http://localhost:11434`
- **Model Name**: `qwen3:4b` (or `qwen3:0.6b` for faster/lighter)
- **Auto-manage server**: âœ… Enabled (automatically starts/stops Ollama)
- **Auto-open notes**: âœ… Enabled (opens summaries after generation)

> **Note:** The preferences dialog is disabled due to freezing issues. Use the Config Editor instead. See [PREFERENCES.md](PREFERENCES.md) for detailed instructions.

### 4. Use It

**Generate Summary:**
- Right-click any paper â†’ **"Generate Summary"**
- Wait 10-30 seconds (varies by model and paper length)
- Summary appears as a note attached to the paper

**Text-to-Speech:**
- Right-click any paper â†’ **"ğŸ”Š Play Summary (TTS)"** - Read the generated summary
- Right-click any paper â†’ **"ğŸ”Š Play Abstract (TTS)"** - Read the paper's abstract
- Right-click any paper â†’ **"ğŸ”Š Play Full Paper (TTS)"** - Read the full PDF (figures/tables/citations removed)

---

## ğŸ¯ Automatic Ollama Management

The plugin automatically manages Ollama for you when **"Auto-manage server"** is enabled:

**What it does:**
1. âœ… **Checks if Ollama is already running** (uses existing instance if available)
2. âœ… **Starts Ollama only if needed** (won't interfere with your existing processes)
3. âœ… **Waits for server to be ready** (handles model loading time)
4. âœ… **Stops Ollama after generation** (frees up VRAM automatically)
5. âœ… **Never stops externally-started servers** (only stops servers it started)

**Benefits:**
- **No manual Ollama management** - just right-click and generate
- **Automatic VRAM cleanup** - frees resources after each use
- **Works with existing Ollama** - detects and uses already-running instances
- **Safe and reliable** - extensive error handling and logging

**Manual control (if preferred):**
- Disable "Auto-manage server" in preferences
- Run `ollama serve` in a terminal yourself
- Plugin will use your running Ollama instance

**Troubleshooting auto-management:**
- Check debug log: **Help â†’ Debug Output Logging â†’ View Output**
- Look for "Ollama Server Manager" messages
- Common issue: Ollama not in PATH â†’ Install via official installer
- Manual fallback: Disable auto-manage and run `ollama serve` yourself

---

## ğŸ”Š Text-to-Speech Features

**Playback Controls:**
- â–¶ï¸ Play / â¸ï¸ Pause / â¹ï¸ Stop
- âª Rewind / â© Fast Forward (skip by 5 chunks)
- ğŸ¢ Speed control (0.5x - 2.0x)
- ğŸ”Š Volume control (0% - 100%)
- ğŸ“Š Progress bar with percentage

**Content Filtering (Full Paper mode):**
- âœ… Removes figures and figure captions
- âœ… Removes tables and table markers
- âœ… Removes footnotes and citation numbers
- âœ… Removes references section
- âœ… Removes page numbers, URLs, emails
- âœ… Filters low-quality paragraphs (data tables, etc.)
- âœ… Fixes common OCR errors

**Three Reading Modes:**
1. **Play Summary** - Reads your generated summary (skips to "Executive Summary" section)
2. **Play Abstract** - Reads the paper's abstract
3. **Play Full Paper** - Reads the entire PDF body text (filtered for clean listening)

---

## ğŸ“ Summary Format

Each generated summary includes:

```
GENERATED SUMMARY: [Paper Title]

Authors: [Author List]
Year: [Publication Year]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Executive Summary
[Comprehensive 2-3 sentence summary covering WHAT, HOW, WHY, RESULTS, and LIMITATIONS]

Key Contributions
â€¢ [Specific contribution with metrics]
â€¢ [Quantifiable result with numbers]
â€¢ [Additional contributions...]

Limitations
â€¢ [Acknowledged limitation 1]
â€¢ [Constraint or failure mode 2]
â€¢ [Additional limitations...]

Innovation Opportunities
â€¢ Xd (Add a dimension): [Extend by adding a dimension - e.g., 2Dâ†’3D, singleâ†’multimodal]
â€¢ X + Y (Combine): [Combine with other tech - e.g., method + quantum computing]
â€¢ X|^ (Given a hammer, find nails): [Apply to new domains - e.g., visionâ†’audioâ†’proteins]
â€¢ X|v (Given a nail, find hammers): [Alternative solutions - e.g., different architectures]
â€¢ X++ (Improve): [Incremental improvements - e.g., faster, more accurate, more robust]
â€¢ Opposite of X (Invert): [Inverse approach - e.g., supervisedâ†’unsupervised, encodeâ†’decode]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Generated by Zotero Summary Creator
```

---

## ğŸ¨ Customization

### Change the LLM Model

**Using Config Editor:**
1. Go to **Edit â†’ Settings â†’ Advanced â†’ Config Editor**
2. Search for: `extensions.summarycreator.ollamaModel`
3. Double-click it and change to your desired model (e.g., `qwen3:0.6b`, `qwen3:4b`, `llama2`)
4. Click OK and restart Zotero
5. Make sure the model is downloaded: `ollama pull qwen3:0.6b`

See [PREFERENCES.md](PREFERENCES.md) for more details.

**Recommended Models:**
- `qwen3:0.6b` - Fastest, lowest VRAM (~512MB) - ideal for laptops or quick summaries
- `qwen3:4b` - **Default** - Good balance of speed/quality (~2.5GB VRAM)
- `llama2` (7B) - Proven quality, ~4GB VRAM
- `mistral` (7B) - Better quality, slightly slower, ~4GB VRAM
- `llama2:13b` - Higher quality, requires ~8GB VRAM
- `codellama` (7B) - Optimized for technical/code-heavy papers

**Qwen3 Models (Recommended for 2024+):**
The Qwen3 series offers excellent performance with lower VRAM requirements:
- `qwen3:0.6b` - Ultra-fast, runs on any laptop
- `qwen3:4b` - Best balance for most users
- `qwen3:7b` - Higher quality for desktop machines
- `qwen3:14b` - Best quality, requires ~8GB+ VRAM

**Install Additional Models:**
```bash
# List available models
ollama list

# Pull Qwen3 models (recommended)
ollama pull qwen3:0.6b    # Fastest, great for laptops
ollama pull qwen3:4b      # Default, good balance
ollama pull qwen3:7b      # Higher quality
ollama pull qwen3:14b     # Best quality

# Pull other models
ollama pull mistral
ollama pull llama2:13b
ollama pull codellama

# Remove models you don't use
ollama rm llama2:13b
```

### Customize the Summary Prompt

The prompt template is in [shared/prompt-template.js](shared/prompt-template.js).

**To modify:**
1. Edit `shared/prompt-template.js`
2. Modify the `buildPromptFromTemplate()` function
3. Rebuild: `npm run build`
4. Reinstall the `.xpi` file in Zotero

**Prompt sections you can customize:**
- Executive summary length and focus
- Which sections to include (contributions, limitations, innovations)
- Innovation framework patterns (Xd, X+Y, X|^, X|v, X++, Opposite of X)
- LaTeX cleanup rules
- Heading formats

**Example customizations:**
```javascript
// Change executive summary length
executiveSummaryLength = '5-7 sentences',

// Add custom section
prompt += `**Practical Applications**
List 3-5 real-world applications of this research:
- Application 1
- Application 2

`;
```

### Adjust TTS Content Filtering

The content filter is in [addon/chrome/content/tts/ContentFilterService.js](addon/chrome/content/tts/ContentFilterService.js).

**Aggressiveness levels:**
- `low` - Minimal filtering, keeps most content
- `medium` - Balanced filtering (default)
- `high` - Aggressive filtering, removes more content

**To change:**
```javascript
// In bootstrap.js, around line 535
const filterService = new ContentFilterService({
  aggressiveness: 'high'  // Change to 'low', 'medium', or 'high'
});
```

**Customizable filters:**
- Figure/table removal patterns
- Footnote markers
- Quality thresholds (paragraph length, article word presence, etc.)
- OCR error corrections

---

## ğŸ”§ Troubleshooting

### Connection Issues

**Problem: "Connection failed" in preferences**

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# If not running, start it
ollama serve

# Check available models
ollama list

# Pull model if missing
ollama pull llama2
```

### Summary Generation Fails

**Common causes:**
1. **No content available** - Paper needs abstract or PDF
2. **Model not found (404 error)** - Run `ollama pull qwen3:4b` to download the model
3. **Wrong model name** - Check settings: **Tools â†’ Summary Creator: Show Current Settings** â†’ Model Name should match an installed model (see [PREFERENCES.md](PREFERENCES.md) to change)
4. **Ollama crashed** - Check `ollama serve` output
5. **Out of VRAM** - Use smaller model: `ollama pull qwen3:0.6b` and change preference to `qwen3:0.6b`

**Debug steps:**
1. **Help â†’ Debug Output Logging â†’ View Output**
2. Click **Enable** and **Clear Output**
3. Try generating summary
4. Look for error messages starting with "Summary Creator:"

### PDF Content Issues

**Problem: "No content available" for PDFs**

1. Right-click PDF â†’ **"Reindex Item"**
2. Wait 30 seconds for indexing
3. Try again

**Advanced PDF diagnostic:**
```javascript
// Tools â†’ Developer â†’ Run JavaScript
const item = Zotero.getActiveZoteroPane().getSelectedItems()[0];
const att = await Zotero.Items.getAsync(item.getAttachments()[0]);
const state = await Zotero.Fulltext.getIndexedState(item.getAttachments()[0]);
return `Indexed: ${state} (0=no, 1=yes, 2=partial)`;
```

### TTS Not Working

**Problem: No sound when playing TTS**

1. Check system volume and unmute
2. Check if other audio works in your browser
3. Look for errors in debug output
4. Try closing and reopening the TTS window

**Problem: TTS reads figures/citations**

- This only happens in "Play Abstract" mode
- Use "Play Full Paper" for filtered content
- Or adjust filter aggressiveness (see Customization section)

---

## ğŸš€ Advanced Usage

### Batch Processing

1. **Select multiple papers** (âŒ˜/Ctrl + click)
2. Right-click â†’ **"Generate Summary"**
3. Progress window shows all items with âœ“/âœ— status
4. Continues on errors (won't stop if one paper fails)

**Batch mode differences:**
- Notes don't auto-open (prevents window spam)
- Errors don't stop processing
- Final summary shows: "Success: X, Failed: Y"

### Export Summaries

Summaries are regular Zotero notes, so you can:
- Export collection to Word/PDF (includes notes)
- Sync via Zotero Sync
- Share via Zotero groups
- Access via Zotero API

### Alternative LLM Services

The plugin works with any OpenAI-compatible API:

**LM Studio:**
```
Ollama URL: http://localhost:1234/v1
```

**LocalAI:**
```
Ollama URL: http://localhost:8080
```

**Custom service:**
Modify `addon/chrome/content/summarycreator.js` to match your API format.

---

## ğŸ“Š Project Structure

```
zotero-summary-creator/
â”œâ”€â”€ addon/                      # Zotero plugin source
â”‚   â”œâ”€â”€ manifest.json           # Plugin metadata
â”‚   â”œâ”€â”€ bootstrap.js            # Plugin lifecycle, UI integration, TTS
â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â””â”€â”€ prompt-template.js  # Customizable prompt template
â”‚   â””â”€â”€ chrome/content/
â”‚       â”œâ”€â”€ summarycreator.js   # Summary generation logic
â”‚       â”œâ”€â”€ preferences.xhtml   # Settings UI
â”‚       â”œâ”€â”€ preferences.js      # Settings logic
â”‚       â””â”€â”€ tts/                # Text-to-Speech modules
â”‚           â”œâ”€â”€ ContentFilterService.js  # PDF content filtering
â”‚           â”œâ”€â”€ TTSService.js            # TTS coordination
â”‚           â””â”€â”€ WebSpeechProvider.js     # Web Speech API wrapper
â”œâ”€â”€ build/                      # Built .xpi file
â”œâ”€â”€ build.js                    # Build script
â””â”€â”€ package.json               # Dependencies and scripts
```

---

## ğŸ”’ Privacy & Security

- âœ… **100% local processing** - All AI runs on your machine
- âœ… **No cloud services** - Paper content never leaves your computer
- âœ… **No tracking** - No analytics, telemetry, or data collection
- âœ… **No internet required** (after model download)
- âœ… **Open source** - Audit the code yourself

**Data flow:**
1. Your Zotero library (local)
2. â†’ PDF text extraction (local, Zotero built-in)
3. â†’ Ollama LLM (local, on your machine)
4. â†’ Generated summary (stored as Zotero note, local)

**Nothing is sent to external servers.**

---

## ğŸ› ï¸ Development

**Build the plugin:**
```bash
# Install dependencies
npm install

# Build the .xpi file
npm run build
```

**Testing:**

The project includes tests for core services (original summary generation features):
```bash
# Run existing tests
npm test

# Watch mode
npm run test:watch

# Coverage report
npm run test:coverage
```

**Note on test coverage:** The original summary generation features (~92% coverage) were built with TDD. The newer TTS features were developed iteratively and don't yet have comprehensive test coverage. Contributions to improve TTS test coverage are welcome!

**Contributing:**
1. Fork the repository
2. Create a feature branch
3. Write tests for new features (especially for TTS!)
4. Submit a pull request

**Code structure:**
- [addon/bootstrap.js](addon/bootstrap.js) - Plugin lifecycle, UI integration, TTS orchestration
- [addon/chrome/content/summarycreator.js](addon/chrome/content/summarycreator.js) - Summary generation logic
- [addon/chrome/content/tts/](addon/chrome/content/tts/) - TTS modules (ContentFilterService, TTSService, WebSpeechProvider)
- [shared/prompt-template.js](shared/prompt-template.js) - Customizable prompt template

---

## ğŸ“š Innovation Framework

The **Innovation Opportunities** section uses six systematic patterns:

1. **Xd (Add a dimension)** - Extend by adding dimensions (2Dâ†’3D, singleâ†’multimodal)
2. **X + Y (Combine)** - Merge with other technologies
3. **X|^ (Hammer â†’ Nails)** - Apply solution to new problem domains
4. **X|v (Nail â†’ Hammers)** - Explore alternative solutions
5. **X++ (Improve)** - Incremental improvements (faster, more accurate, more robust)
6. **Opposite of X (Invert)** - Explore inverse approaches

This framework helps identify research opportunities systematically.

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details

---

## ğŸ™ Credits

- Built with [Ollama](https://ollama.ai) for local LLM inference
- Text-to-Speech powered by Web Speech API
- Inspired by the need for efficient academic paper comprehension

---

## ğŸ†˜ Support

**Before reporting issues:**
1. âœ… Check Ollama is running: `curl http://localhost:11434/api/tags`
2. âœ… Check model is installed: `ollama list` (should show `qwen3:4b` or your chosen model)
3. âœ… Check plugin installed: **Tools â†’ Add-ons**
4. âœ… Review current settings: **Tools â†’ Summary Creator: Show Current Settings**
5. âœ… Check debug output: **Help â†’ Debug Output Logging â†’ View Output**

**Common fixes:**
- Install model: `ollama pull qwen3:4b`
- Verify model name in preferences matches installed model
- Restart Ollama: `ollama serve`
- Restart Zotero
- Reinstall plugin
- Reindex PDFs (right-click â†’ Reindex Item)

**Report issues:**
Open an issue on GitHub with:
- Zotero version
- Plugin version
- Ollama model used
- Debug output (Help â†’ Debug Output Logging)
- Steps to reproduce

---

**Get Started:** Right-click any paper in Zotero â†’ Generate Summary! ğŸš€
